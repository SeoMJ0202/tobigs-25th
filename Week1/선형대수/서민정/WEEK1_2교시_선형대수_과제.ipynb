{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d41915c",
      "metadata": {
        "id": "9d41915c"
      },
      "source": [
        "## 1주차 - 기초선형대수 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607e69d9",
      "metadata": {
        "id": "607e69d9"
      },
      "source": [
        "안녕하세요 투빅스 여러분 24기 이상민입니다.   \n",
        "1주차 정규세션 다들 고생하셨습니다.   \n",
        "모두에게 유익한 시간이었기를 바랍니다.   \n",
        "선형대수내용과 관련하여 간단한 과제들을 출제했습니다.   \n",
        "첫 주차이기에 간단한 내용들로만 구성해보았으니 문제를 잘 읽어보시고 과제 수행해주시기바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b98b0c",
      "metadata": {
        "id": "15b98b0c"
      },
      "source": [
        "### Q1. 이론문제(서술형)\n",
        "#### 우리는 신경망이 단순히 선형변환(행렬 곱)만으로 이루어지지 않고, 중간에 비선형 함수(Non-linear function)가 반드시 필요하다는 것을 배웠습니다.\n",
        "\n",
        "##### 1-1. 선형변환을 여러 번 겹쳐서 수행했을 때 여전히 '선형적'인 성질이 유지된다는 것이 어떤 의미인지 설명하고,\n",
        "\n",
        "##### 1-2. 이를 통해 딥러닝 모델에서 활성화 함수(Activation Function)와 같은 비선형성이 왜 필수적인지 서술하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0b3d12",
      "metadata": {
        "id": "4e0b3d12"
      },
      "source": [
        "---\n",
        "**정답 입력**\n",
        "\n",
        "1-1 : 선형변환을 여러 번 겹친다는 것은 수학적으로 행렬의 곱으로 표현된다. 예를 들어, 두 개의 층을 가진 선형 모델이 있다고 가정해보겠다.\n",
        "\n",
        "\n",
        "*   첫 번째 층의 변환: $y_1 = W_1x$\n",
        "*   두 번째 층의 변환:  $y_2 = W_2y_1$\n",
        "\n",
        "이를 결합하면 $y_2 = W_2(W_1x) = (W_2W_1)x$가 된다. 여기서 핵심은 두 행렬의 곱 $W_2W_1$ 역시 하나의 행렬 $W_{new}$로 치환될 수 있다는 점이다.\n",
        "\n",
        "즉, 층을 100층, 1000층 쌓더라도 활성화 함수가 없다면 결국 입력값에 행렬 하나를 곱하는 단일 선형 변환과 수학적으로 완전히 동일해진다. 모델의 깊이를 늘리는 것이 표현력의 확장으로 이어지지 않고, 여전히 입력과 출력 사이의 직선적인 관계만을 설명할 수 있게 됨을 의미한다.\n",
        "\n",
        "1-2 : 첫 번째, 복잡한 데이터 패턴의 모사를 위해서이다. 현실 세계의 데이터는 단순히 직선이나 평면으로 구분할 수 없는 매우 복잡하고 뒤틀린 구조를 가지고 있다. 비선형 활성화 함수는 공간을 왜곡시키거나 꺾음으로써 모델이 이러한 비선형적인 결정 경계를 형성할 수 있게 한다.\n",
        "\n",
        "두 번째, 다층 구조의 유효성 확보를 위해서이다. 비선형 함수가 중간에 끼어들어야만 각 층의 출력이 단순히 다음 층의 입력으로 합쳐지지 않고, 층이 쌓일수록 더 고차원적이고 추상적인 특징을 추출할 수 있다. 이것이 가능해야 비로소 딥러닝의 의미가 살아난다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5daedf55",
      "metadata": {
        "id": "5daedf55"
      },
      "source": [
        "### Q2. 개념 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc15efb5",
      "metadata": {
        "id": "fc15efb5"
      },
      "source": [
        "#### 2-1. **[내적(Dot Product)과 Norm]**   \n",
        "##### 두 벡터의 유사도를 판단하거나 길이를 구할 때 사용되는 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f34a19fb",
      "metadata": {
        "id": "f34a19fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_similarity_components(v1, v2):\n",
        "    \"\"\"\n",
        "    v1, v2: numpy array (1D vectors)\n",
        "    반환값: 두 벡터의 내적 값, v1의 norm, v2의 norm\n",
        "    \"\"\"\n",
        "    # 1. 두 벡터의 내적(Dot Product)을 계산하세요.\n",
        "    dot_prod = np.dot(v1, v2)\n",
        "\n",
        "    # 2. 각 벡터의 크기(Norm, L2 Norm)를 계산하세요.\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "\n",
        "    return dot_prod, norm_v1, norm_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ac9c2ab",
      "metadata": {
        "id": "9ac9c2ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bf0a19-3fe9-4712-f13f-a92dad2d6b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내적값 : 56.0, v1의 norm : 5.0, v2의 norm : 13.0\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "v1 = np.array([3.0, 4.0])  # 예시 벡터 1\n",
        "v2 = np.array([12.0, 5.0])  # 예시 벡터 2\n",
        "out = calculate_similarity_components(v1, v2)\n",
        "\n",
        "print(f\"내적값 : {out[0]}, v1의 norm : {out[1]}, v2의 norm : {out[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf443749",
      "metadata": {
        "id": "cf443749"
      },
      "source": [
        "#### 2-2. **[선형변환 (행렬 곱)]**\n",
        "##### 입력 벡터를 다른 차원의 공간으로 매핑하는 선형변환 과정입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a7e127e",
      "metadata": {
        "id": "5a7e127e"
      },
      "outputs": [],
      "source": [
        "def linear_transformation(x, W, b):\n",
        "    \"\"\"\n",
        "    x: 입력 벡터 (input features)\n",
        "    W: 가중치 행렬 (weight matrix)\n",
        "    b: 편향 벡터 (bias)\n",
        "    반환값: 선형변환 결과 z = Wx + b\n",
        "    \"\"\"\n",
        "    # 1. 행렬 곱(Matrix Multiplication) Wx를 수행하세요.\n",
        "    # 힌트: numpy의 행렬 곱 연산자(@) 또는 np.dot, np.matmul 사용\n",
        "    wx = W @ x\n",
        "\n",
        "    # 2. 편향(bias)을 더하세요.\n",
        "    z = wx + b\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "01b29ac6",
      "metadata": {
        "id": "01b29ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd11ef86-a762-4444-a6ed-d001764fb7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.6 0.3]\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "x = np.array([1.0, 2.0])  # 예시 input vector\n",
        "W = np.array([[0.5, 1.0], [1.5, -0.5]])  # 예시 weight matrix\n",
        "b = np.array([0.1, -0.2])  # 예시 bias vector\n",
        "\n",
        "print(linear_transformation(x, W, b))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1125f25d",
      "metadata": {
        "id": "1125f25d"
      },
      "source": [
        "#### 2-3. **[비선형성 (ReLU 함수)]**\n",
        "##### 선형변환 결과에 비선형성을 부여하는 활성화 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0e5215",
      "metadata": {
        "id": "ad0e5215"
      },
      "source": [
        "![ReLU](https://velog.velcdn.com/images/sasganamabeer/post/4ea7fb74-2c3a-423f-8e47-bde64cddebb2/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%2C%202021-05-13%2015-27-54.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8cc17868",
      "metadata": {
        "id": "8cc17868"
      },
      "outputs": [],
      "source": [
        "def relu_function(z):\n",
        "    \"\"\"\n",
        "    z: 선형변환을 거친 값\n",
        "    반환값: 0보다 작으면 0, 0보다 크면 그대로 반환 (max(0, z))\n",
        "    \"\"\"\n",
        "    # numpy의 maximum 함수 등을 사용하여 ReLU를 구현하세요.\n",
        "    a = np.maximum(0, z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "176c1447",
      "metadata": {
        "id": "176c1447"
      },
      "source": [
        "### Q3. 응용 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1508a9",
      "metadata": {
        "id": "6a1508a9"
      },
      "source": [
        "위 2번 문제에서 작성한 힘수들(calculate_similarity_components, linear_transformation, relu_function)을 활용하여 아래 문제를 해결하는 코드를 작성하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1474f9b",
      "metadata": {
        "id": "f1474f9b"
      },
      "source": [
        "#### 간단한 유사도 기반 분류기 구현.\n",
        "입력 데이터 x가 주어졌을 때, 1차적으로 선형 변환과 비선형 변환을 거쳐 특징(feature)을 추출하고, 이 추출된 특징이 기준 벡터(reference vector)와 얼마나 유사한지 코사인 유사도(Cosine Similarity)로 판단합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6b4d9ed7",
      "metadata": {
        "id": "6b4d9ed7"
      },
      "outputs": [],
      "source": [
        "def forward_and_evaluate(x, W, b, ref_vector):\n",
        "    \"\"\"\n",
        "    x: 입력 벡터\n",
        "    W: 가중치 행렬\n",
        "    b: 편향 벡터\n",
        "    ref_vector: 비교 대상이 되는 기준 벡터\n",
        "    반환값: 추출된 특징 벡터와 기준 벡터 사이의 코사인 유사도\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. 선형 변환\n",
        "    # 입력 공간의 x를 W와 b를 통해 잠재 공간(Latent Space)으로 매핑한다.\n",
        "    z = linear_transformation(x, W, b)\n",
        "\n",
        "    # 2. 비선형 활성화\n",
        "    # 선형 변환된 값 z에 ReLU를 적용하여 최종 특징(Feature) 벡터 a를 얻는다.\n",
        "    a = relu_function(z)\n",
        "\n",
        "    # 3. 코사인 유사도 계산\n",
        "    # 특징 벡터 a와 기준 벡터 ref_vector 사이의 내적과 각각의 크기(Norm)를 구한다.\n",
        "    dot_prod, norm_a, norm_ref = calculate_similarity_components(a, ref_vector)\n",
        "\n",
        "    # 코사인 유사도 공식 적용 (분모가 0이 아님을 가정)\n",
        "    # 코사인 유사도 = 내적 / (벡터a의 크기 * 벡터ref의 크기)\n",
        "    cosine_sim = dot_prod / (norm_a * norm_ref)\n",
        "\n",
        "    return cosine_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c04901de",
      "metadata": {
        "id": "c04901de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2d7289-078c-43ad-dcf0-1c6b2dd8c46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6708203932499369\n"
          ]
        }
      ],
      "source": [
        "# 테스트 코드\n",
        "x = np.array([1, 2])\n",
        "W = np.array([[1, -1], [2, 0], [0, 1]]) # 3x2 행렬\n",
        "b = np.array([0, 1, -1])\n",
        "ref = np.array([1, 1, 0])\n",
        "print(forward_and_evaluate(x, W, b, ref))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d09e9a",
      "metadata": {
        "id": "f4d09e9a"
      },
      "source": [
        "+자유롭게 다른 활성화함수를 정의하는 등을 통해 추가적으로 학습하셔도 좋을것 같습니다.\n",
        "\n",
        "고생하셨습니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d2d1b1",
      "metadata": {
        "id": "18d2d1b1"
      },
      "source": [
        "### **과제 완료 후 잊지말고 꼭 깃허브에 제출해주시기바랍니다.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}